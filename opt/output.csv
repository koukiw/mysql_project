project_name,path,file_name,file_format,text,create_date,upload_date,json_data
project1,project1/honyarara.pdf,honyarara.pdf,pdf,筑波大学大学院博士課程システム情報工学研究科修士論文最適化に基づくマージン付きサイズ均等クラスタリングアルゴリズム石田　紗知子修士（工学）（リスク工学専攻）指導教員 遠藤 靖典2017 年 3 月概要　クラスタリングとは，データ解析の一手法であり，外的基準なしに自動的に個体の集合の分類を行う，教師なし分類の一種である．この手法を用いることにより，対象となるデータ間の類似性や関連性を明らかにし，そのように分類されたデータから，有益な情報を得ることが出来るとされており，現在ではマーケティングなど幅広い場面で利用されている．　そのようなクラスタリング手法の 1 つにサイズ均等クラスタリングがある．サイズ均等クラスタリングは，各クラスタの持つ個体数が均等かつクラスタ内距離の総和を最小にするようなクラスタリング手法であり，最適化に基づく手法として，最適化に基づくサイズ均等クラスタリング（Even-sized Clustering Based on Optimization：ECBO）が提案された．ECBO は，k-means の目的関数と制約条件に，新たにクラスタサイズを均等にするという制約を加え，シンプレックス法に基づき，目的関数の最適化を行うことにより，各クラスタに所属する個体数（クラスタサイズ）を均等にするクラスタリング手法である．通常のクラスタリング手法では，クラスタサイズを任意の均等な数に分割することが出来ないのに対し，ECBO では，任意のクラスタ数・クラスタサイズで均等に分割できるという利点がある．そのため，この手法は，荷物の配送計画を組む際に，配送対象となる住宅地域を分割するといったスケジューリング問題や，企業のタスクを分配するといった最適化問題に有用であると考えられる．　現在提案されている ECBO は，クラスタサイズを完全に均等にするという制約のもと分類を行うため，クラスタサイズにある程度のあそびを許し，完全に均等な個体数に分ける必要が無いような場合には，不便である．　そこで，本研究では，既存のクラスタリング手法のアルゴリズムを利用し，クラスタサイズに一定の幅を持たせた，最適化に基づくマージン付きサイズ均等クラスタリング（Even-sizedwith Margin Clustering based on Optimization：(cid:11)-ECBO）のアルゴリズムの手法を提案する．　本論文では，サイズ均等クラスタリングの一種である K-Member Clustering（KMC），既存手法である ECBO の手法・課題を示し，それらの問題に対するアプローチとして，既存のクラスタリング手法のアルゴリズムを利用した，最適化に基づくマージン付きサイズ均等クラスタリングの手法を 6 つ提案する．そして，人工データや Iris データ等の実データを用いた数値例を通して，提案する手法の有効性の評価・考察を行う．目 次第 1 章 序論1.1 背景 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.2 目的 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.3 本論文の構成 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :第 2 章 クラスタリングの様々な手法2.1 クラスタリングとは : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2 類似性尺度 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2.1 ユークリッド距離を用いた非類似性尺度 : : : : : : : : : : : : : : : :2.2.2 コサイン相関を用いた類似性尺度 : : : : : : : : : : : : : : : : : : : :2.2.3 L1 ノルムを用いた非類似性尺度 : : : : : : : : : : : : : : : : : : : : :k-means: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-means++ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-medoids : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.6.1 カーネル関数を利用したクラスタリング : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.32.42.52.6 Kernel k-means2.7 L1 k-means第 3 章 サイズ均等クラスタリング3.1 K-Member Clustering : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.1 K-匿名化について : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.2 Greedy K-member Clustering（GKC） : : : : : : : : : : : : : : : : : :3.1.3 One-pass K-means Algorithm for k-anonymization（OKA） : : : : : : :3.1.4 Clustering-Based k-Anonymity（CBK） : : : : : : : : : : : : : : : : :3.2 最適化に基づくサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : :第 4 章 提案手法4.1 (cid:11)-ECBO：k-means に基づくアルゴリズム : : : : : : : : : : : : : : : : : : : :4.2 (cid:11)-ECBO++：k-means++に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.3 (cid:11)-MECBO：k-medoids に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.4 (cid:11)-KECBO：Kernel k-means に基づくアルゴリズム : : : : : : : : : : : : : : :4.5 (cid:11)-L1ECBO：L1 ノルムを用いたアルゴリズム : : : : : : : : : : : : : : : : :i11223344556778910121212131314151717181919194.6 (cid:11)-cosine-ECBO：コサイン類似度を用いたアルゴリズム : : : : : : : : : : : :第 5 章 数値例5.1 Adjusted Rand Index : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2 人工データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.1 密度の異なる円状のデータ : : : : : : : : : : : : : : : : : : : : : : : :2 重円データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.25.2.3 個体数が異なる標準正規分布に従ったデータ : : : : : : : : : : : : : :5.2.4 密度・半径の異なる円状のデータ : : : : : : : : : : : : : : : : : : : :3 次元データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.55.3 実データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Fisher’s Iris データ : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.3.15.3.2 Wisconsin Breast Cancer データ : : : : : : : : : : : : : : : : : : : : : :第 6 章 結論謝辞参考文献202424242529323741434345485051ii図 目 次5.1 密度の異なる円状のデータ（個体数 255 個） : : : : : : : : : : : : : : : : : :25k-means による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.25.3 ECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.4 (cid:11)-ECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : : :275.5 (cid:11)-MECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : :275.6 (cid:11)-KECBO による分類結果 ((cid:11)=38): : : : : : : : : : : : : : : : : : : : : : : :275.7 (cid:11)-L1ECBO による分類結果 ((cid:11)=26) : : : : : : : : : : : : : : : : : : : : : : : :275.8 (cid:11)-cosine-ECBO による分類結果 ((cid:11)=10): : : : : : : : : : : : : : : : : : : : :275.9 (cid:11)-ECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : : :285.10 (cid:11)-ECBO++を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.11 (cid:11)-MECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.12 (cid:11)-KECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : :285.13 (c,20230510184703,20230510184703,"{""test"":""hoge""}"
project1,project1/詳細/KITAJIMA.pdf,KITAJIMA.pdf,pdf,筑波大学大学院博士課程システム情報工学研究科修士論文サイズ均等クラスタリングのファジィ化に関する研究北島　慧修士（工学）（リスク工学専攻 ）指導教員 遠藤　靖典2019 年 3 月概要クラスタリングの一手法として，最適化に基づくサイズ均等クラスタリング (ECBO) が提案されている．通常のクラスタリング手法はクラスタサイズに制約を設けていないため，クラスタサイズに大きな差があるような結果を返すことがある．それに対し，ECBO は全てのクラスタのサイズを均等とするように分割を行う．そのため，配送計画問題やタスク分配問題といったクラスタサイズが均等である分割が好ましい場合に有用である．しかし，ECBOで設定されているクラスタサイズの制約は非常に厳しいため，クラスタサイズをある程度揃えたい場合に不便であった．この問題に対し，2 方面から問題の解決がなされた．1 つ目は，クラスタサイズの制約に幅を持たせる方法である．クラスタサイズの制約に幅を持たせ，それを調整することでクラスタサイズの制約の強さを調整できるようになる．このような発想から，最適化に基づくマージン付きサイズ均等クラスタリング (COCBO) が提案されている．もう 1 つの方法は，帰属度をファジィ化することである．この方法では，帰属度がより柔軟な値をとることができるため，ECBO と比較してクラスタサイズの制約を緩和することができる．この観点から，ファジィサイズ均等クラスタリング (FECBO) が提案された．さて，上にあげたアルゴリズムはいずれも HCM や FCM に制約条件を加えた手法と見做すことができる．HCM や FCM は非常に多く利用されているアルゴリズムであるが，外れ値やノイズに対して強く影響を受けることが問題である．このような問題はサイズ均等クラスタリングにおいても同様に見受けられる．しかし，サイズ均等クラスタリングのロバスト性についての検討は十分になされていない．本研究では，これらのサイズ均等クラスタリングのロバスト性の検討を行うとともに，ノイズクラスタリングを用いた新たな手法の提案を行う．また，HCM のもう一つの短所として，クラスタリング結果が初期値によって大きく異なることが挙げられる．初期値の選択方法を変えることで，局所解への収束を減らすことができれば，クラスタリング結果を安定して得られる，計算コストを削減できるというメリットがある．そこで，本研究では ECBO を用いて HCM の初期値依存の改善を行う手法を提案する．目 次第 1 章 序論1.1 背景 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.2 目的 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.3 本論文の構成 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :第 2 章 主要なクラスタリング手法2.1 クラスタリングについて : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2 Hard c-means2.3 Fuzzy c-means : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.4 ノイズクラスタリング : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.5 最適化に基づくサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : :第 3 章 サイズ均等クラスタリングの発展3.1 マージン付きサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : : :3.2 ファジィサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : : : : : :第 4 章 サイズ均等クラスタリングのロバスト性についての検討4.1 クラスタリングアルゴリズムのノイズに対するロバスト性について : : : : :4.2 既存のアルゴリズム : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.2.1 Medoid COCBO : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.2.2 L1-COCBO : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.3 提案手法 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.3.1 COntrolled-sized Noise Clustering : : : : : : : : : : : : : : : : : : : : :Fuzzy Even-sized Noise Clustering : : : : : : : : : : : : : : : : : : : :4.3.2第 5 章 サイズ均等クラスタリングを用いた HCM の初期値依存の改善5.1 クラスタリングアルゴリズムの初期値依存性について : : : : : : : : : : : : :k-means++ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.25.3 サイズ均等クラスタリングに基づく HCM の初期値設定法 : : : : : : : : : : :第 6 章 数値例6.1 Adjusted Rand Index : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.2 ロバスト性の評価 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :i11234467891010111313131314161616181818192020216.2.1 外れ値を含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : :6.2.2 一様ノイズを含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : :6.2.3 ノイズを加えた Fisher’s Iris Dataset: : : : : : : : : : : : : : : : : : :6.3 初期値依存性の評価 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.3.1 人工データ：クラスタ間距離が大きいデータ : : : : : : : : : : : : : :6.3.2 人工データ：クラスタ間距離が小さいデータ : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : :6.3.36.3.4 Breast Cancer Wisconsin Data Set : : : : : : : : : : : : : : : : : : : : :Fisher’s Iris Dataset第 7 章 結論謝辞参考文献2124272828303132343536ii図 目 次6.1 外れ値を含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : : : : : :6.2 FENC による分類結果 ((cid:14) = 4:0): : : : : : : : : : : : : : : : : : : : : : : : :6.3 CONC による分類結果 ((cid:14) = 4:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.4 Medoid COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : :6.5 L1-COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : :6.6 FECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.7 COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.8 一様なノイズを含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : : :6.9 FENC による分類結果 ((cid:14) = 3:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.10 CONC による分類結果 ((cid:14) = 3:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.11 Medoid COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : :6.12 L1-COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : :6.13 FECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.14 COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.15 クラスタ間距離が大きいデータ : : : : : : : : : : : : : : : : : : : : : : : : :6.16 大域解への収束例 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.17 局所解への収束例 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.18 クラスタ間距離が小さいデータ : : : : : : : : : : : : : : : : : : : : : : : : :212222222223232425252525262628292931iii第 1 章 序論1.1 背景近年のスマートフォンの普及や Internet of Things (IoT) の浸透によってデータの収集，蓄積が非常に容易となった．また，Web 上の行動だけでなく，GPS を利用した位置情報やポイントカード，クレ,20230510184703,20230510184703,"{""test"":""hoge""}"
project1,project1/資料/2016_HIRANO2.pdf,2016_HIRANO2.pdf,pdf,"筑波大学大学院博士課程システム情報工学研究科修士論文最適化に基づくサイズ均等クラスタリング手法に関する研究平野 翼修士（工学）（リスク工学専攻）指導教員 遠藤 靖典2016 年 3 月概要クラスタリングはデータ解析に用いられる手法であり，個体の集合であるデータセットに対し教師なし分類を行う．この手法はデータマイニングを始めとして様々な場面で利用されている．中でも K-member Clustering (KMC) は各クラスタが少なくとも K 個の個体を持ち，クラスタ内距離の総和を最小にするクラスタリング手法であり，情報セキュリティにおいて重要な手法である K-匿名化への応用が期待されている．しかしながら，KMC の既存手法は不自然な分類が行われることが多く，K-匿名化を行う際の情報損失が大きくなってしまうことが問題であった．この原因として既存手法は最適化に基づいてないということが挙げられる．クラスタリングの代表的手法である Hard c-means (HCM) や Fuzzy c-means は目的関数の最適化を行っており，KMC においても最適化を用いることでより良い分類結果を得ることが期待できる．一方，クラスタサイズの制約について，均等な大きさに分割することを考える．これはサイズ均等クラスタリングと呼ばれ，K-匿名化にも応用できる他，運送エリアの分割問題やタスク分配の問題等，応用の幅は広い．以上の背景から，最適化に基づくサイズ均等クラスタリング (Even-sized Clustering AlgorithmBased on Optimization; ECBO) が提案されている．これは HCM の目的関数および制約式に関し，クラスタサイズを均等にする制約式を加え，目的関数の最適化を行うことによりサイズを均等にするクラスタリングを行う手法である．ECBO は HCM が基となっているため，初期値問題や外れ値に対するロバスト性，線形分離となることが問題となる．20 世紀後半から研究されてきたクラスタリング手法全体をみれば，このような問題に対応する手法は多く存在している．そこで，本研究ではこれらの問題に対し，既存のクラスタリング手法の考え方やアルゴリズムを利用したサイズ均等クラスタリングの手法を 4 つ提案する．さらに，複数のデータセットに対する数値例を通してこれらの手法について考察する．目 次第 1 章 序論1.1 背景 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.2 目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.3 本論文の構成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 2 章 種々のクラスタリング手法2.1 クラスタリングについて . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.2 Hard c-means2.3 Fuzzy c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .k-means++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.42.5 L1 Fuzzy c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .k-medoids . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.62.7 Kernel Hard c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1133445667811第 3 章 サイズ均等クラスタリング3.1 サイズ均等クラスタリングについて . . . . . . . . . . . . . . . . . . . . . . .3.2 K-member Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3.2.1 Greedy K-member Clustering . . . . . . . . . . . . . . . . . . . . . . .3.2.2 One-pass k-means Algorithm for K-anonymization . . . . . . . . . . . .3.2.3 Clustering-based K-anonymity . . . . . . . . . . . . . . . . . . . . . .3.2.4 Two-division Clustering for K-anonymity of Cluster Maximization . . . .3.3 サイズ均等クラスタリング . . . . . . . . . . . . . . . . . . . . . . . . . . . .13131415151618183.3.1 Extended Two-division Clustering for K-anonymity of Cluster Maximization 19203.4 最適化に基づくサイズ均等クラスタリング . . . . . . . . . . . . . . . . . . .第 4 章 提案手法4.1 ECBO++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.2 L1 ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.3 Medoid ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.4 Kernel ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 5 章 数値例5.1 情報損失関数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .23232325252727i5.2 人工データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2.1 ノイズ入りデータ . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2.2 二重円データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.3 実データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Iris データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.3.15.3.2 地図データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 6 章 結論謝辞参考文献272730333333363839ii図 目 次5.1 ノイズ入りデータ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2 ノイズ入りデータに対する ECBO および ECBO++の結果 (IL= 397.748). . .5.3 ノイズ入りデータに対する KECBO の結果 (IL= 378.66) . . . . . . . . . . . .5.4 ノイズ入りデータに対する L1ECBO の結果 (IL= 413.37). . . . . . . . . . .5.5 ノイズ入りデータに対する Medoid ECBO の結果 (IL= 382.37). . . . . . . .5.6 二重円データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.7 二重円データに対する ECBO の結果 (IL= 185.00). . . . . . . . . . . . . . .5.8 二重円データに対する KECBO の結果 (IL= 181.23). . . . . . . . . . . . . .5.9 二重円データに対する ECBO の結果 (IL= 130.65). . . . . . . . . . . . . . .5.10 二重円データに対する KECBO の結果 (IL= 134.32). . . . . . . . . . . . . .5.11 二重円データに対する L1ECBO の結果 (IL= 127.77) . . . . . . . . . . . . . .5.12 茨城県つくば市豊里の杜の衛星写真 (google map より) . . . . . . . . . . . . .282929292930313132323234iii表 目 次5.1 ノイズ入りデータにおける各手法での IL 値および実行時間 . . . . . . . . . .5.2 二重円データにおける各手法での最良の IL 値 . . . . . . . . . . . . . . . . .5.3 二重円データにおける各手法での平均実行時間 [ms] . . . . . . . . . . . . . .Iris データにおける各手法での値 . . . . . . . . . . . . . . . . . . . . . . . . .5.45.5 地図データにおける各手法での最良の IL 値 . . . . . . . . . . . . . . . . . . .5.6 地図データにおける各手法の平均実行時間 [ms]. . . . . . . . . . . . . . . .5.7 ECBO,ECBO++の IL 値の平均と分散 . . . . . . . . . . . . . . . . . . . . . .28313134353535iv第 1 章 序論1.1 背景近年のインターネットの普及やコンピュータの性能の向上によって，膨大な量のデータの収集・蓄積が非常に容易となっている．コンビニエンスストアでの購買データや，スマートデバイスによる行動履歴データといった，不特定多数のユーザーから集められるこのようなデータはビッグデータと呼ばれ，多くの企業で",20230510184703,20230510184703,"{""test"":""hoge""}"
project1,project1/資料/Fujipress_JACIII-2.pdf,Fujipress_JACIII-2.pdf,pdf,"Paper:Fuzziﬁed Even-Sized Clustering Based on OptimizationFuzziﬁed Even-Sized Clustering Based on OptimizationKei Kitajima∗, Yasunori Endo∗∗, and Yukihiro Hamasuna∗∗∗∗Department of Risk Engineering, Graduate School of Systems and Information Engineering, University of Tsukuba1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, JapanE-mail: s1720624@s.tsukuba.ac.jp∗∗Faculty of Engineering, Information and Systems, University of Tsukuba1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, JapanE-mail: endo@risk.tsukuba.ac.jp∗∗∗Department of Informatics, School of Science and Engineering, Kindai University3-4-1 Kowakae, Higashiosaka, Osaka 577-8502, JapanE-mail: yhama@info.kindai.ac.jp[Received December 20, 2017; accepted April 12, 2018]Clustering is a method of data analysis without theuse of supervised data. Even-sized clustering basedon optimization (ECBO) is a clustering algorithm thatfocuses on cluster size with the constraints that clus-ter sizes must be the same. However, this constraintsmakes ECBO inconvenient to apply in cases where acertain margin of cluster size is allowed. It is believedthat this issue can be overcome by applying a fuzzyclustering method. Fuzzy clustering can represent themembership of data to clusters more ﬂexible. In thispaper, we propose a new even-sized clustering algo-rithm based on fuzzy clustering and verify its effec-tiveness through numerical examples.Keywords: clustering, machine learning, even-sized,fuzzy1. IntroductionClustering is a method of machine learning for dataanalysis, in which a given dataset is automatically clas-siﬁed into clusters. K-means [1] (KM) and fuzzy c-means [2] (FCM) are established clustering methodsbased on optimization. In these methods, the value of theobjective function [3, 4] can be used as an evaluation in-dex of the clustering result. From this point of view, manyclustering methods are modeled as optimization problemswith objective functions and constraints.K-member clustering (KMC) has been proposed as amethod that focuses on cluster size. KMC classiﬁes adataset into clusters whose size is at least K. KMC isexpected to be applied to k-anonymization and task distri-bution problems. Representatively, the following three al-gorithms can be mentioned: greedy k-member clustering(GKC) [5], one-pass k-means (OKA) [6], and clustering-based k-anonymity (CBK) [7]. These conventional meth-ods sometimes yield unnatural classiﬁcation results, Thisis because these methods are not based on the optimiza-In addition, as a relatedtion of the objective function.study focusing on cluster size, there is a method introduc-ing size control variables [8].Microaggregation has been proposed as a method basedon optimization [9, 10]. This method works under con-straints that the size of each cluster is greater than or equalto K and less than or equal to 2K. Microaggregation hasdemonstorated great results with K-anonymization.Some authors have also proposed even-sized clusteringbased on optimization (ECBO) [11, 12] as a method basedon optimization. The constraint considered in the ECBOis that each cluster size is K or K + 1. ECBO is con-structed by adding cluster size constraints to KM, and themembership of each object is obtained by iteratively op-timizing the objective function using the simplex method.Numerical experiments show that ECBO demonstoratessuitable results.Since the constraints considered in the ECBO are so se-vere, it is inconvenient if each cluster size does not need tobe even. For example, when classifying 100 objects intothree clusters, each cluster size set to 33 or 34 in ECBO.However, it may be sufﬁcient to set each cluster size toapproximately 30 in many cases. In such cases, ECBOis inconvenient due to severe constraints. Better cluster-ing results are expected by relaxing severe constraints ofcluster size.There are two methods to solve the above problem.The ﬁrst is to relax cluster size constraints directly. Con-cretely, the parameter K is given a certain width α.Inthis method,the degree of the cluster size constraintcan be controlled by varying α. From this point ofview, some authors have proposed a clustering algo-rithm based on ECBO. The proposed algorithm is referredto as controlled sized clustering based on optimization(COCBO) [13, 14] since each cluster size can be con-trolled. The second is fuzziﬁcation of the membership.In this method, the membership can be represented moreﬂexibly, and as a result, the constraints are relaxed. Thismethod can be considered to be fuzziﬁcation of ECBO; inother words, it is constructed by adding size constraints toFCM.In this paper, a clustering algorithm based on the sec-Vol.22 No.4, 2018Journal of Advanced Computational Intelligenceand Intelligent Informatics537Kitajima, K., Endo, Y., and Hamasuna, Y.ond method is proposed, and the methods are evaluatedthrough numerical examples.Algorithm 1 FCMStep 1. Give the constant c.2. Fuzzy c-Means and Even-Sized ClusteringBased on OptimizationIn this section, FCM and ECBO are introduced",20230510184703,20230510184703,"{""test"":""hoge""}"
project1,project1/資料/IFSA-SCIS_2017_final_55_version2.pdf,IFSA-SCIS_2017_final_55_version2.pdf,pdf,"Controlled-sized ClusteringBased on OptimizationYasunori EndoFaculty of Eng., Info. & Sys.University of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: endo@risk.tsukuba.ac.jpSachiko IshidaDepartment of Risk EngineeringGraduate School of Sys. & Info. Eng.University of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: s1520570@u.tsukuba.ac.jpNaohiko KinoshitaResearch Fellow of JSPSUniversity of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: kinoshita@risk.tsukuba.ac.jpAbstract—Clustering is one of unsupervised classiﬁcationmethod, that is, it classiﬁes a data set into some clusterswithout any external criterion. Typical clustering methods,e.g. k-means (KM) and fuzzy c-means (FCM) are constructedbased on optimization of the given objective function. Manyclustering methods as well as KM and FCM are formulated asoptimization problems with typical objective functions andconstraints. The objective function itself is also an evaluationguideline of results of clustering methods. Consideringtogether with its theoretical extensibility, there is the greatadvantage to construct clustering methods in the frameworkof optimization. From the viewpoint of optimization, someof the authors proposed an even-sized clustering methodbased on optimization (ECBO), which is with strengthenedconstraints of cluster size, and constructed some variationsof ECBO. The constraint considered in ECBO is that eachcluster size is K or K + 1. ECBO is based on KM andits algorithm is constructed as iterative optimization. Thebelongingness of each object to clusters are calculated by thesimplex method in each iteration. The numerical experimentsshow that ECBO has higher classiﬁcation accuracy thanother similar clustering methods. It is considered that ECBOhas the advantage in the viewpoint of clustering accuracy,cluster size, and optimization framework than other similarmethods. However, the constraint of cluster sizes of ECBO isstrict so that it may be inconvenient in case that the partitionresults, of which each cluster size need not be strictly even,but uneven, is desirable. Moreover, it is expected that newclustering algorithms of which each cluster size can becontrolled can deal with more various datasets. In this paper,we ﬁrst propose two new clustering algorithms based onECBO. Each cluster size can be controlled in the proposedalgorithms. Next, we estimate the new clustering algorithmsthrough some numerical experiments.I. IntroductionClustering is one of the data mining techniques andit classiﬁes a dataset into some clusters automatically.K-member clustering (KMC) is one of the clusteringmethod and it classiﬁes a dataset into some clusters ofwhich the size is at least K. The following three methodsare known as typical KMC methods: greedy k-memberclustering (GKC) [1], one-pass k-means (KM) algorithmfor K-anonymization (OKA) [2], and clustering-based K-anonymity (CBK) [3].978-1-5090-4917-2/17$31.00 c⃝ 2017 IEEEConventional KMC methods including GKC, OKA,and CBK have some problems for classifying a datasetinto some clusters of which the size is at least K. Theclusters by GKC and OKA have sometimes no sense ofunity. The cluster number is not maximized under theconstraint that the size of each cluster is or more than Kby CBK.To solve the problem of CBK, two-division clusteringfor K-anonymity of cluster maximization (2DCKM) wasproposed and extended by one of the authors which isreferred to as extended two-division clustering for K-anonymity of cluster maximization (E2DCKM) [4]. Both2DCKM and E2DCKM are based on CBK, then they ob-tain ﬁnal cluster division from iteration of classiﬁcationof one cluster into two clusters and adjustment of eachcluster size. These KMC methods classify a dataset intoclusters of which the size is at least K. However, theclassiﬁcation accuracy of the above methods is not sohigh. One of the reason is that those methods is notbased on optimization.A clustering algorithm based on graph theory, whichclassiﬁes a dataset into some even-sized clusters, wasproposed [5]. However, it is also not based on optimiza-tion.Typical clustering methods, e.g. KM and fuzzy c-means (FCM) are constructed based on optimizationof the given objective function [6]. Many clusteringmethods as well as KM and FCM are formulated asoptimization problems with typical objective functionsand constraints. The objective function itself is also anevaluation guideline of results of clustering methods.Considering together with its theoretical extensibility,there is the great advantage to construct clusteringmethods in the framework of optimization. From theviewpoint of optimization, some of the authors proposedan even-sized clustering method based on optimiza-tion (ECBO) [7], [8], which is with more strengthenedconstraints of cluster size than KMC, and constructedsome variations of ECBO. The constraint considered inECBO is that each cluster size is K or K + 1. Here wehave to notice that the existence of the cluster numberIFSA-SCIS 2017, Otsu, Shiga, Japan, June 27",20230510184703,20230510184703,"{""test"":""hoge""}"
project2,project2/KITAJIMA2.pdf,KITAJIMA2.pdf,pdf,筑波大学大学院博士課程システム情報工学研究科修士論文サイズ均等クラスタリングのファジィ化に関する研究北島　慧修士（工学）（リスク工学専攻 ）指導教員 遠藤　靖典2019 年 3 月概要クラスタリングの一手法として，最適化に基づくサイズ均等クラスタリング (ECBO) が提案されている．通常のクラスタリング手法はクラスタサイズに制約を設けていないため，クラスタサイズに大きな差があるような結果を返すことがある．それに対し，ECBO は全てのクラスタのサイズを均等とするように分割を行う．そのため，配送計画問題やタスク分配問題といったクラスタサイズが均等である分割が好ましい場合に有用である．しかし，ECBOで設定されているクラスタサイズの制約は非常に厳しいため，クラスタサイズをある程度揃えたい場合に不便であった．この問題に対し，2 方面から問題の解決がなされた．1 つ目は，クラスタサイズの制約に幅を持たせる方法である．クラスタサイズの制約に幅を持たせ，それを調整することでクラスタサイズの制約の強さを調整できるようになる．このような発想から，最適化に基づくマージン付きサイズ均等クラスタリング (COCBO) が提案されている．もう 1 つの方法は，帰属度をファジィ化することである．この方法では，帰属度がより柔軟な値をとることができるため，ECBO と比較してクラスタサイズの制約を緩和することができる．この観点から，ファジィサイズ均等クラスタリング (FECBO) が提案された．さて，上にあげたアルゴリズムはいずれも HCM や FCM に制約条件を加えた手法と見做すことができる．HCM や FCM は非常に多く利用されているアルゴリズムであるが，外れ値やノイズに対して強く影響を受けることが問題である．このような問題はサイズ均等クラスタリングにおいても同様に見受けられる．しかし，サイズ均等クラスタリングのロバスト性についての検討は十分になされていない．本研究では，これらのサイズ均等クラスタリングのロバスト性の検討を行うとともに，ノイズクラスタリングを用いた新たな手法の提案を行う．また，HCM のもう一つの短所として，クラスタリング結果が初期値によって大きく異なることが挙げられる．初期値の選択方法を変えることで，局所解への収束を減らすことができれば，クラスタリング結果を安定して得られる，計算コストを削減できるというメリットがある．そこで，本研究では ECBO を用いて HCM の初期値依存の改善を行う手法を提案する．目 次第 1 章 序論1.1 背景 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.2 目的 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.3 本論文の構成 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :第 2 章 主要なクラスタリング手法2.1 クラスタリングについて : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2 Hard c-means2.3 Fuzzy c-means : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.4 ノイズクラスタリング : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.5 最適化に基づくサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : :第 3 章 サイズ均等クラスタリングの発展3.1 マージン付きサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : : :3.2 ファジィサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : : : : : :第 4 章 サイズ均等クラスタリングのロバスト性についての検討4.1 クラスタリングアルゴリズムのノイズに対するロバスト性について : : : : :4.2 既存のアルゴリズム : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.2.1 Medoid COCBO : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.2.2 L1-COCBO : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.3 提案手法 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :4.3.1 COntrolled-sized Noise Clustering : : : : : : : : : : : : : : : : : : : : :Fuzzy Even-sized Noise Clustering : : : : : : : : : : : : : : : : : : : :4.3.2第 5 章 サイズ均等クラスタリングを用いた HCM の初期値依存の改善5.1 クラスタリングアルゴリズムの初期値依存性について : : : : : : : : : : : : :k-means++ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.25.3 サイズ均等クラスタリングに基づく HCM の初期値設定法 : : : : : : : : : : :第 6 章 数値例6.1 Adjusted Rand Index : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.2 ロバスト性の評価 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :i11234467891010111313131314161616181818192020216.2.1 外れ値を含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : :6.2.2 一様ノイズを含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : :6.2.3 ノイズを加えた Fisher’s Iris Dataset: : : : : : : : : : : : : : : : : : :6.3 初期値依存性の評価 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.3.1 人工データ：クラスタ間距離が大きいデータ : : : : : : : : : : : : : :6.3.2 人工データ：クラスタ間距離が小さいデータ : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : :6.3.36.3.4 Breast Cancer Wisconsin Data Set : : : : : : : : : : : : : : : : : : : : :Fisher’s Iris Dataset第 7 章 結論謝辞参考文献2124272828303132343536ii図 目 次6.1 外れ値を含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : : : : : :6.2 FENC による分類結果 ((cid:14) = 4:0): : : : : : : : : : : : : : : : : : : : : : : : :6.3 CONC による分類結果 ((cid:14) = 4:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.4 Medoid COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : :6.5 L1-COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : :6.6 FECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.7 COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.8 一様なノイズを含む 2 クラスのデータ : : : : : : : : : : : : : : : : : : : : : :6.9 FENC による分類結果 ((cid:14) = 3:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.10 CONC による分類結果 ((cid:14) = 3:0) : : : : : : : : : : : : : : : : : : : : : : : : :6.11 Medoid COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : :6.12 L1-COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : :6.13 FECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.14 COCBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.15 クラスタ間距離が大きいデータ : : : : : : : : : : : : : : : : : : : : : : : : :6.16 大域解への収束例 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.17 局所解への収束例 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :6.18 クラスタ間距離が小さいデータ : : : : : : : : : : : : : : : : : : : : : : : : :212222222223232425252525262628292931iii第 1 章 序論1.1 背景近年のスマートフォンの普及や Internet of Things (IoT) の浸透によってデータの収集，蓄積が非常に容易となった．また，Web 上の行動だけでなく，GPS を利用した位置情報やポイントカード，クレ,20230510184703,20230510184703,"{""test"":""hoge""}"
project2,project2/クラスタリング論文/2016_HIRANO2.pdf,2016_HIRANO2.pdf,pdf,"筑波大学大学院博士課程システム情報工学研究科修士論文最適化に基づくサイズ均等クラスタリング手法に関する研究平野 翼修士（工学）（リスク工学専攻）指導教員 遠藤 靖典2016 年 3 月概要クラスタリングはデータ解析に用いられる手法であり，個体の集合であるデータセットに対し教師なし分類を行う．この手法はデータマイニングを始めとして様々な場面で利用されている．中でも K-member Clustering (KMC) は各クラスタが少なくとも K 個の個体を持ち，クラスタ内距離の総和を最小にするクラスタリング手法であり，情報セキュリティにおいて重要な手法である K-匿名化への応用が期待されている．しかしながら，KMC の既存手法は不自然な分類が行われることが多く，K-匿名化を行う際の情報損失が大きくなってしまうことが問題であった．この原因として既存手法は最適化に基づいてないということが挙げられる．クラスタリングの代表的手法である Hard c-means (HCM) や Fuzzy c-means は目的関数の最適化を行っており，KMC においても最適化を用いることでより良い分類結果を得ることが期待できる．一方，クラスタサイズの制約について，均等な大きさに分割することを考える．これはサイズ均等クラスタリングと呼ばれ，K-匿名化にも応用できる他，運送エリアの分割問題やタスク分配の問題等，応用の幅は広い．以上の背景から，最適化に基づくサイズ均等クラスタリング (Even-sized Clustering AlgorithmBased on Optimization; ECBO) が提案されている．これは HCM の目的関数および制約式に関し，クラスタサイズを均等にする制約式を加え，目的関数の最適化を行うことによりサイズを均等にするクラスタリングを行う手法である．ECBO は HCM が基となっているため，初期値問題や外れ値に対するロバスト性，線形分離となることが問題となる．20 世紀後半から研究されてきたクラスタリング手法全体をみれば，このような問題に対応する手法は多く存在している．そこで，本研究ではこれらの問題に対し，既存のクラスタリング手法の考え方やアルゴリズムを利用したサイズ均等クラスタリングの手法を 4 つ提案する．さらに，複数のデータセットに対する数値例を通してこれらの手法について考察する．目 次第 1 章 序論1.1 背景 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.2 目的 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1.3 本論文の構成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 2 章 種々のクラスタリング手法2.1 クラスタリングについて . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.2 Hard c-means2.3 Fuzzy c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .k-means++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.42.5 L1 Fuzzy c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .k-medoids . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .2.62.7 Kernel Hard c-means . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1133445667811第 3 章 サイズ均等クラスタリング3.1 サイズ均等クラスタリングについて . . . . . . . . . . . . . . . . . . . . . . .3.2 K-member Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3.2.1 Greedy K-member Clustering . . . . . . . . . . . . . . . . . . . . . . .3.2.2 One-pass k-means Algorithm for K-anonymization . . . . . . . . . . . .3.2.3 Clustering-based K-anonymity . . . . . . . . . . . . . . . . . . . . . .3.2.4 Two-division Clustering for K-anonymity of Cluster Maximization . . . .3.3 サイズ均等クラスタリング . . . . . . . . . . . . . . . . . . . . . . . . . . . .13131415151618183.3.1 Extended Two-division Clustering for K-anonymity of Cluster Maximization 19203.4 最適化に基づくサイズ均等クラスタリング . . . . . . . . . . . . . . . . . . .第 4 章 提案手法4.1 ECBO++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.2 L1 ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.3 Medoid ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4.4 Kernel ECBO . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 5 章 数値例5.1 情報損失関数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .23232325252727i5.2 人工データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2.1 ノイズ入りデータ . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2.2 二重円データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.3 実データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Iris データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.3.15.3.2 地図データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .第 6 章 結論謝辞参考文献272730333333363839ii図 目 次5.1 ノイズ入りデータ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.2 ノイズ入りデータに対する ECBO および ECBO++の結果 (IL= 397.748). . .5.3 ノイズ入りデータに対する KECBO の結果 (IL= 378.66) . . . . . . . . . . . .5.4 ノイズ入りデータに対する L1ECBO の結果 (IL= 413.37). . . . . . . . . . .5.5 ノイズ入りデータに対する Medoid ECBO の結果 (IL= 382.37). . . . . . . .5.6 二重円データ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .5.7 二重円データに対する ECBO の結果 (IL= 185.00). . . . . . . . . . . . . . .5.8 二重円データに対する KECBO の結果 (IL= 181.23). . . . . . . . . . . . . .5.9 二重円データに対する ECBO の結果 (IL= 130.65). . . . . . . . . . . . . . .5.10 二重円データに対する KECBO の結果 (IL= 134.32). . . . . . . . . . . . . .5.11 二重円データに対する L1ECBO の結果 (IL= 127.77) . . . . . . . . . . . . . .5.12 茨城県つくば市豊里の杜の衛星写真 (google map より) . . . . . . . . . . . . .282929292930313132323234iii表 目 次5.1 ノイズ入りデータにおける各手法での IL 値および実行時間 . . . . . . . . . .5.2 二重円データにおける各手法での最良の IL 値 . . . . . . . . . . . . . . . . .5.3 二重円データにおける各手法での平均実行時間 [ms] . . . . . . . . . . . . . .Iris データにおける各手法での値 . . . . . . . . . . . . . . . . . . . . . . . . .5.45.5 地図データにおける各手法での最良の IL 値 . . . . . . . . . . . . . . . . . . .5.6 地図データにおける各手法の平均実行時間 [ms]. . . . . . . . . . . . . . . .5.7 ECBO,ECBO++の IL 値の平均と分散 . . . . . . . . . . . . . . . . . . . . . .28313134353535iv第 1 章 序論1.1 背景近年のインターネットの普及やコンピュータの性能の向上によって，膨大な量のデータの収集・蓄積が非常に容易となっている．コンビニエンスストアでの購買データや，スマートデバイスによる行動履歴データといった，不特定多数のユーザーから集められるこのようなデータはビッグデータと呼ばれ，多くの企業で",20230510184703,20230510184703,"{""test"":""hoge""}"
project2,project2/クラスタリング論文/Fujipress_JACIII-2.pdf,Fujipress_JACIII-2.pdf,pdf,"Paper:Fuzziﬁed Even-Sized Clustering Based on OptimizationFuzziﬁed Even-Sized Clustering Based on OptimizationKei Kitajima∗, Yasunori Endo∗∗, and Yukihiro Hamasuna∗∗∗∗Department of Risk Engineering, Graduate School of Systems and Information Engineering, University of Tsukuba1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, JapanE-mail: s1720624@s.tsukuba.ac.jp∗∗Faculty of Engineering, Information and Systems, University of Tsukuba1-1-1 Tennodai, Tsukuba, Ibaraki 305-8573, JapanE-mail: endo@risk.tsukuba.ac.jp∗∗∗Department of Informatics, School of Science and Engineering, Kindai University3-4-1 Kowakae, Higashiosaka, Osaka 577-8502, JapanE-mail: yhama@info.kindai.ac.jp[Received December 20, 2017; accepted April 12, 2018]Clustering is a method of data analysis without theuse of supervised data. Even-sized clustering basedon optimization (ECBO) is a clustering algorithm thatfocuses on cluster size with the constraints that clus-ter sizes must be the same. However, this constraintsmakes ECBO inconvenient to apply in cases where acertain margin of cluster size is allowed. It is believedthat this issue can be overcome by applying a fuzzyclustering method. Fuzzy clustering can represent themembership of data to clusters more ﬂexible. In thispaper, we propose a new even-sized clustering algo-rithm based on fuzzy clustering and verify its effec-tiveness through numerical examples.Keywords: clustering, machine learning, even-sized,fuzzy1. IntroductionClustering is a method of machine learning for dataanalysis, in which a given dataset is automatically clas-siﬁed into clusters. K-means [1] (KM) and fuzzy c-means [2] (FCM) are established clustering methodsbased on optimization. In these methods, the value of theobjective function [3, 4] can be used as an evaluation in-dex of the clustering result. From this point of view, manyclustering methods are modeled as optimization problemswith objective functions and constraints.K-member clustering (KMC) has been proposed as amethod that focuses on cluster size. KMC classiﬁes adataset into clusters whose size is at least K. KMC isexpected to be applied to k-anonymization and task distri-bution problems. Representatively, the following three al-gorithms can be mentioned: greedy k-member clustering(GKC) [5], one-pass k-means (OKA) [6], and clustering-based k-anonymity (CBK) [7]. These conventional meth-ods sometimes yield unnatural classiﬁcation results, Thisis because these methods are not based on the optimiza-In addition, as a relatedtion of the objective function.study focusing on cluster size, there is a method introduc-ing size control variables [8].Microaggregation has been proposed as a method basedon optimization [9, 10]. This method works under con-straints that the size of each cluster is greater than or equalto K and less than or equal to 2K. Microaggregation hasdemonstorated great results with K-anonymization.Some authors have also proposed even-sized clusteringbased on optimization (ECBO) [11, 12] as a method basedon optimization. The constraint considered in the ECBOis that each cluster size is K or K + 1. ECBO is con-structed by adding cluster size constraints to KM, and themembership of each object is obtained by iteratively op-timizing the objective function using the simplex method.Numerical experiments show that ECBO demonstoratessuitable results.Since the constraints considered in the ECBO are so se-vere, it is inconvenient if each cluster size does not need tobe even. For example, when classifying 100 objects intothree clusters, each cluster size set to 33 or 34 in ECBO.However, it may be sufﬁcient to set each cluster size toapproximately 30 in many cases. In such cases, ECBOis inconvenient due to severe constraints. Better cluster-ing results are expected by relaxing severe constraints ofcluster size.There are two methods to solve the above problem.The ﬁrst is to relax cluster size constraints directly. Con-cretely, the parameter K is given a certain width α.Inthis method,the degree of the cluster size constraintcan be controlled by varying α. From this point ofview, some authors have proposed a clustering algo-rithm based on ECBO. The proposed algorithm is referredto as controlled sized clustering based on optimization(COCBO) [13, 14] since each cluster size can be con-trolled. The second is fuzziﬁcation of the membership.In this method, the membership can be represented moreﬂexibly, and as a result, the constraints are relaxed. Thismethod can be considered to be fuzziﬁcation of ECBO; inother words, it is constructed by adding size constraints toFCM.In this paper, a clustering algorithm based on the sec-Vol.22 No.4, 2018Journal of Advanced Computational Intelligenceand Intelligent Informatics537Kitajima, K., Endo, Y., and Hamasuna, Y.ond method is proposed, and the methods are evaluatedthrough numerical examples.Algorithm 1 FCMStep 1. Give the constant c.2. Fuzzy c-Means and Even-Sized ClusteringBased on OptimizationIn this section, FCM and ECBO are introduced",20230510184703,20230510184703,"{""test"":""hoge""}"
project2,project2/クラスタリング論文/IFSA-SCIS_2017_final_55_version2.pdf,IFSA-SCIS_2017_final_55_version2.pdf,pdf,"Controlled-sized ClusteringBased on OptimizationYasunori EndoFaculty of Eng., Info. & Sys.University of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: endo@risk.tsukuba.ac.jpSachiko IshidaDepartment of Risk EngineeringGraduate School of Sys. & Info. Eng.University of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: s1520570@u.tsukuba.ac.jpNaohiko KinoshitaResearch Fellow of JSPSUniversity of TsukubaTsukuba, Ibaraki, 305-8573, JapanEmail: kinoshita@risk.tsukuba.ac.jpAbstract—Clustering is one of unsupervised classiﬁcationmethod, that is, it classiﬁes a data set into some clusterswithout any external criterion. Typical clustering methods,e.g. k-means (KM) and fuzzy c-means (FCM) are constructedbased on optimization of the given objective function. Manyclustering methods as well as KM and FCM are formulated asoptimization problems with typical objective functions andconstraints. The objective function itself is also an evaluationguideline of results of clustering methods. Consideringtogether with its theoretical extensibility, there is the greatadvantage to construct clustering methods in the frameworkof optimization. From the viewpoint of optimization, someof the authors proposed an even-sized clustering methodbased on optimization (ECBO), which is with strengthenedconstraints of cluster size, and constructed some variationsof ECBO. The constraint considered in ECBO is that eachcluster size is K or K + 1. ECBO is based on KM andits algorithm is constructed as iterative optimization. Thebelongingness of each object to clusters are calculated by thesimplex method in each iteration. The numerical experimentsshow that ECBO has higher classiﬁcation accuracy thanother similar clustering methods. It is considered that ECBOhas the advantage in the viewpoint of clustering accuracy,cluster size, and optimization framework than other similarmethods. However, the constraint of cluster sizes of ECBO isstrict so that it may be inconvenient in case that the partitionresults, of which each cluster size need not be strictly even,but uneven, is desirable. Moreover, it is expected that newclustering algorithms of which each cluster size can becontrolled can deal with more various datasets. In this paper,we ﬁrst propose two new clustering algorithms based onECBO. Each cluster size can be controlled in the proposedalgorithms. Next, we estimate the new clustering algorithmsthrough some numerical experiments.I. IntroductionClustering is one of the data mining techniques andit classiﬁes a dataset into some clusters automatically.K-member clustering (KMC) is one of the clusteringmethod and it classiﬁes a dataset into some clusters ofwhich the size is at least K. The following three methodsare known as typical KMC methods: greedy k-memberclustering (GKC) [1], one-pass k-means (KM) algorithmfor K-anonymization (OKA) [2], and clustering-based K-anonymity (CBK) [3].978-1-5090-4917-2/17$31.00 c⃝ 2017 IEEEConventional KMC methods including GKC, OKA,and CBK have some problems for classifying a datasetinto some clusters of which the size is at least K. Theclusters by GKC and OKA have sometimes no sense ofunity. The cluster number is not maximized under theconstraint that the size of each cluster is or more than Kby CBK.To solve the problem of CBK, two-division clusteringfor K-anonymity of cluster maximization (2DCKM) wasproposed and extended by one of the authors which isreferred to as extended two-division clustering for K-anonymity of cluster maximization (E2DCKM) [4]. Both2DCKM and E2DCKM are based on CBK, then they ob-tain ﬁnal cluster division from iteration of classiﬁcationof one cluster into two clusters and adjustment of eachcluster size. These KMC methods classify a dataset intoclusters of which the size is at least K. However, theclassiﬁcation accuracy of the above methods is not sohigh. One of the reason is that those methods is notbased on optimization.A clustering algorithm based on graph theory, whichclassiﬁes a dataset into some even-sized clusters, wasproposed [5]. However, it is also not based on optimiza-tion.Typical clustering methods, e.g. KM and fuzzy c-means (FCM) are constructed based on optimizationof the given objective function [6]. Many clusteringmethods as well as KM and FCM are formulated asoptimization problems with typical objective functionsand constraints. The objective function itself is also anevaluation guideline of results of clustering methods.Considering together with its theoretical extensibility,there is the great advantage to construct clusteringmethods in the framework of optimization. From theviewpoint of optimization, some of the authors proposedan even-sized clustering method based on optimiza-tion (ECBO) [7], [8], which is with more strengthenedconstraints of cluster size than KMC, and constructedsome variations of ECBO. The constraint considered inECBO is that each cluster size is K or K + 1. Here wehave to notice that the existence of the cluster numberIFSA-SCIS 2017, Otsu, Shiga, Japan, June 27",20230510184703,20230510184703,"{""test"":""hoge""}"
project2,project2/クラスタリング論文/ISHIDA2.pdf,ISHIDA2.pdf,pdf,筑波大学大学院博士課程システム情報工学研究科修士論文最適化に基づくマージン付きサイズ均等クラスタリングアルゴリズム石田　紗知子修士（工学）（リスク工学専攻）指導教員 遠藤 靖典2017 年 3 月概要　クラスタリングとは，データ解析の一手法であり，外的基準なしに自動的に個体の集合の分類を行う，教師なし分類の一種である．この手法を用いることにより，対象となるデータ間の類似性や関連性を明らかにし，そのように分類されたデータから，有益な情報を得ることが出来るとされており，現在ではマーケティングなど幅広い場面で利用されている．　そのようなクラスタリング手法の 1 つにサイズ均等クラスタリングがある．サイズ均等クラスタリングは，各クラスタの持つ個体数が均等かつクラスタ内距離の総和を最小にするようなクラスタリング手法であり，最適化に基づく手法として，最適化に基づくサイズ均等クラスタリング（Even-sized Clustering Based on Optimization：ECBO）が提案された．ECBO は，k-means の目的関数と制約条件に，新たにクラスタサイズを均等にするという制約を加え，シンプレックス法に基づき，目的関数の最適化を行うことにより，各クラスタに所属する個体数（クラスタサイズ）を均等にするクラスタリング手法である．通常のクラスタリング手法では，クラスタサイズを任意の均等な数に分割することが出来ないのに対し，ECBO では，任意のクラスタ数・クラスタサイズで均等に分割できるという利点がある．そのため，この手法は，荷物の配送計画を組む際に，配送対象となる住宅地域を分割するといったスケジューリング問題や，企業のタスクを分配するといった最適化問題に有用であると考えられる．　現在提案されている ECBO は，クラスタサイズを完全に均等にするという制約のもと分類を行うため，クラスタサイズにある程度のあそびを許し，完全に均等な個体数に分ける必要が無いような場合には，不便である．　そこで，本研究では，既存のクラスタリング手法のアルゴリズムを利用し，クラスタサイズに一定の幅を持たせた，最適化に基づくマージン付きサイズ均等クラスタリング（Even-sizedwith Margin Clustering based on Optimization：(cid:11)-ECBO）のアルゴリズムの手法を提案する．　本論文では，サイズ均等クラスタリングの一種である K-Member Clustering（KMC），既存手法である ECBO の手法・課題を示し，それらの問題に対するアプローチとして，既存のクラスタリング手法のアルゴリズムを利用した，最適化に基づくマージン付きサイズ均等クラスタリングの手法を 6 つ提案する．そして，人工データや Iris データ等の実データを用いた数値例を通して，提案する手法の有効性の評価・考察を行う．目 次第 1 章 序論1.1 背景 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.2 目的 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.3 本論文の構成 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :第 2 章 クラスタリングの様々な手法2.1 クラスタリングとは : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2 類似性尺度 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2.1 ユークリッド距離を用いた非類似性尺度 : : : : : : : : : : : : : : : :2.2.2 コサイン相関を用いた類似性尺度 : : : : : : : : : : : : : : : : : : : :2.2.3 L1 ノルムを用いた非類似性尺度 : : : : : : : : : : : : : : : : : : : : :k-means: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-means++ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-medoids : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.6.1 カーネル関数を利用したクラスタリング : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.32.42.52.6 Kernel k-means2.7 L1 k-means第 3 章 サイズ均等クラスタリング3.1 K-Member Clustering : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.1 K-匿名化について : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.2 Greedy K-member Clustering（GKC） : : : : : : : : : : : : : : : : : :3.1.3 One-pass K-means Algorithm for k-anonymization（OKA） : : : : : : :3.1.4 Clustering-Based k-Anonymity（CBK） : : : : : : : : : : : : : : : : :3.2 最適化に基づくサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : :第 4 章 提案手法4.1 (cid:11)-ECBO：k-means に基づくアルゴリズム : : : : : : : : : : : : : : : : : : : :4.2 (cid:11)-ECBO++：k-means++に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.3 (cid:11)-MECBO：k-medoids に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.4 (cid:11)-KECBO：Kernel k-means に基づくアルゴリズム : : : : : : : : : : : : : : :4.5 (cid:11)-L1ECBO：L1 ノルムを用いたアルゴリズム : : : : : : : : : : : : : : : : :i11223344556778910121212131314151717181919194.6 (cid:11)-cosine-ECBO：コサイン類似度を用いたアルゴリズム : : : : : : : : : : : :第 5 章 数値例5.1 Adjusted Rand Index : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2 人工データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.1 密度の異なる円状のデータ : : : : : : : : : : : : : : : : : : : : : : : :2 重円データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.25.2.3 個体数が異なる標準正規分布に従ったデータ : : : : : : : : : : : : : :5.2.4 密度・半径の異なる円状のデータ : : : : : : : : : : : : : : : : : : : :3 次元データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.55.3 実データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Fisher’s Iris データ : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.3.15.3.2 Wisconsin Breast Cancer データ : : : : : : : : : : : : : : : : : : : : : :第 6 章 結論謝辞参考文献202424242529323741434345485051ii図 目 次5.1 密度の異なる円状のデータ（個体数 255 個） : : : : : : : : : : : : : : : : : :25k-means による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.25.3 ECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.4 (cid:11)-ECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : : :275.5 (cid:11)-MECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : :275.6 (cid:11)-KECBO による分類結果 ((cid:11)=38): : : : : : : : : : : : : : : : : : : : : : : :275.7 (cid:11)-L1ECBO による分類結果 ((cid:11)=26) : : : : : : : : : : : : : : : : : : : : : : : :275.8 (cid:11)-cosine-ECBO による分類結果 ((cid:11)=10): : : : : : : : : : : : : : : : : : : : :275.9 (cid:11)-ECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : : :285.10 (cid:11)-ECBO++を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.11 (cid:11)-MECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.12 (cid:11)-KECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : :285.13 (c,20230510184703,20230510184703,"{""test"":""hoge""}"
single_file,honyararaのコピー.pdf,honyararaのコピー.pdf,pdf,筑波大学大学院博士課程システム情報工学研究科修士論文最適化に基づくマージン付きサイズ均等クラスタリングアルゴリズム石田　紗知子修士（工学）（リスク工学専攻）指導教員 遠藤 靖典2017 年 3 月概要　クラスタリングとは，データ解析の一手法であり，外的基準なしに自動的に個体の集合の分類を行う，教師なし分類の一種である．この手法を用いることにより，対象となるデータ間の類似性や関連性を明らかにし，そのように分類されたデータから，有益な情報を得ることが出来るとされており，現在ではマーケティングなど幅広い場面で利用されている．　そのようなクラスタリング手法の 1 つにサイズ均等クラスタリングがある．サイズ均等クラスタリングは，各クラスタの持つ個体数が均等かつクラスタ内距離の総和を最小にするようなクラスタリング手法であり，最適化に基づく手法として，最適化に基づくサイズ均等クラスタリング（Even-sized Clustering Based on Optimization：ECBO）が提案された．ECBO は，k-means の目的関数と制約条件に，新たにクラスタサイズを均等にするという制約を加え，シンプレックス法に基づき，目的関数の最適化を行うことにより，各クラスタに所属する個体数（クラスタサイズ）を均等にするクラスタリング手法である．通常のクラスタリング手法では，クラスタサイズを任意の均等な数に分割することが出来ないのに対し，ECBO では，任意のクラスタ数・クラスタサイズで均等に分割できるという利点がある．そのため，この手法は，荷物の配送計画を組む際に，配送対象となる住宅地域を分割するといったスケジューリング問題や，企業のタスクを分配するといった最適化問題に有用であると考えられる．　現在提案されている ECBO は，クラスタサイズを完全に均等にするという制約のもと分類を行うため，クラスタサイズにある程度のあそびを許し，完全に均等な個体数に分ける必要が無いような場合には，不便である．　そこで，本研究では，既存のクラスタリング手法のアルゴリズムを利用し，クラスタサイズに一定の幅を持たせた，最適化に基づくマージン付きサイズ均等クラスタリング（Even-sizedwith Margin Clustering based on Optimization：(cid:11)-ECBO）のアルゴリズムの手法を提案する．　本論文では，サイズ均等クラスタリングの一種である K-Member Clustering（KMC），既存手法である ECBO の手法・課題を示し，それらの問題に対するアプローチとして，既存のクラスタリング手法のアルゴリズムを利用した，最適化に基づくマージン付きサイズ均等クラスタリングの手法を 6 つ提案する．そして，人工データや Iris データ等の実データを用いた数値例を通して，提案する手法の有効性の評価・考察を行う．目 次第 1 章 序論1.1 背景 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.2 目的 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :1.3 本論文の構成 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :第 2 章 クラスタリングの様々な手法2.1 クラスタリングとは : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2 類似性尺度 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.2.1 ユークリッド距離を用いた非類似性尺度 : : : : : : : : : : : : : : : :2.2.2 コサイン相関を用いた類似性尺度 : : : : : : : : : : : : : : : : : : : :2.2.3 L1 ノルムを用いた非類似性尺度 : : : : : : : : : : : : : : : : : : : : :k-means: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-means++ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :k-medoids : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.6.1 カーネル関数を利用したクラスタリング : : : : : : : : : : : : : : : :: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :2.32.42.52.6 Kernel k-means2.7 L1 k-means第 3 章 サイズ均等クラスタリング3.1 K-Member Clustering : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.1 K-匿名化について : : : : : : : : : : : : : : : : : : : : : : : : : : : :3.1.2 Greedy K-member Clustering（GKC） : : : : : : : : : : : : : : : : : :3.1.3 One-pass K-means Algorithm for k-anonymization（OKA） : : : : : : :3.1.4 Clustering-Based k-Anonymity（CBK） : : : : : : : : : : : : : : : : :3.2 最適化に基づくサイズ均等クラスタリング : : : : : : : : : : : : : : : : : : :第 4 章 提案手法4.1 (cid:11)-ECBO：k-means に基づくアルゴリズム : : : : : : : : : : : : : : : : : : : :4.2 (cid:11)-ECBO++：k-means++に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.3 (cid:11)-MECBO：k-medoids に基づくアルゴリズム : : : : : : : : : : : : : : : : :4.4 (cid:11)-KECBO：Kernel k-means に基づくアルゴリズム : : : : : : : : : : : : : : :4.5 (cid:11)-L1ECBO：L1 ノルムを用いたアルゴリズム : : : : : : : : : : : : : : : : :i11223344556778910121212131314151717181919194.6 (cid:11)-cosine-ECBO：コサイン類似度を用いたアルゴリズム : : : : : : : : : : : :第 5 章 数値例5.1 Adjusted Rand Index : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2 人工データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.1 密度の異なる円状のデータ : : : : : : : : : : : : : : : : : : : : : : : :2 重円データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.25.2.3 個体数が異なる標準正規分布に従ったデータ : : : : : : : : : : : : : :5.2.4 密度・半径の異なる円状のデータ : : : : : : : : : : : : : : : : : : : :3 次元データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.2.55.3 実データ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :Fisher’s Iris データ : : : : : : : : : : : : : : : : : : : : : : : : : : : :5.3.15.3.2 Wisconsin Breast Cancer データ : : : : : : : : : : : : : : : : : : : : : :第 6 章 結論謝辞参考文献202424242529323741434345485051ii図 目 次5.1 密度の異なる円状のデータ（個体数 255 個） : : : : : : : : : : : : : : : : : :25k-means による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.25.3 ECBO による分類結果 : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :265.4 (cid:11)-ECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : : :275.5 (cid:11)-MECBO による分類結果 ((cid:11)=27) : : : : : : : : : : : : : : : : : : : : : : : :275.6 (cid:11)-KECBO による分類結果 ((cid:11)=38): : : : : : : : : : : : : : : : : : : : : : : :275.7 (cid:11)-L1ECBO による分類結果 ((cid:11)=26) : : : : : : : : : : : : : : : : : : : : : : : :275.8 (cid:11)-cosine-ECBO による分類結果 ((cid:11)=10): : : : : : : : : : : : : : : : : : : : :275.9 (cid:11)-ECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : : :285.10 (cid:11)-ECBO++を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.11 (cid:11)-MECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : :285.12 (cid:11)-KECBO を用いたときの Margin の変化に伴う目的関数と ARI の変遷 : : : :285.13 (c,20230510184703,20230510184703,"{""test"":""hoge""}"
